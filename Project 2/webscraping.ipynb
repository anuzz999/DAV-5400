{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of Your Project\n",
    "### Author: Your Name\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this Jupyter Notebook, I document the process of web scraping for Project 2 - Task 3. The focus is on extracting [type of data, e.g., product listings, article entries, weather data] from [website name], which is a [brief description of the website and its relevance].\n",
    "\n",
    "This notebook includes:\n",
    "- Setup and import of scraping modules\n",
    "- Initialization and use of the `LinkScraper` class to collect relevant links\n",
    "- Utilization of the `DataScraper` class to extract detailed information\n",
    "- Initial data exploration to understand the dataset\n",
    "- Discussion of the dataset's potential applications and the meaning of its fields\n",
    "\n",
    "The code repository for this project can be found at [GitHub Repository URL](#).\n",
    "\n",
    "**Please note**: Web scraping has been conducted in accordance with the website's `robots.txt` file and terms of service, ensuring that scraping is permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To begin scraping, we need to set up our environment. This involves importing the custom scraping classes we've defined in our Python package. We'll also establish any initial parameters required for the scraping process, such as the base URL of the website we intend to scrape and any specific class names that guide the scraping process.\n",
    "\n",
    "The `LinkScraper` class will gather the necessary links from the website, and the `DataScraper` class will extract detailed data from each page linked. These classes are part of a Python package named 'my_scraping_package', which is structured as an installable package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and modules\n",
    "from webscraping import LinkScraper, DataScraper\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base URL of the website we will be scraping\n",
    "base_url = 'https://www.yellowpagesnepal.com/'\n",
    "\n",
    "# If needed, define any other parameters such as class names or identifiers that will guide the scraping process\n",
    "# class_names = ['class1', 'class2', 'class3', ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the LinkScraper\n",
    "\n",
    "Now that our environment is set up, we can begin the scraping process. The first step is to initialize our `LinkScraper` class, which is designed to navigate through the website and collect all relevant links. These links will be the targets for our detailed data scraping later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Class Names for Scraping\n",
    "\n",
    "In accordance with the project guidelines, I will now specify the class names corresponding to the sections of the website that contain the data of interest. These class names have been determined by inspecting the website's HTML structure and identifying the containers that hold the relevant data.\n",
    "\n",
    "This targeted approach allows us to collect a dataset with specific information that we will describe and analyze. The chosen dataset is unique within the class and will be used to answer several questions related to [describe the type of analysis or questions of interest].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.yellowpagesnepal.com/abhi-raj-thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.yellowpagesnepal.com/dowellsonic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.yellowpagesnepal.com/puantistres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.yellowpagesnepal.com/bahuvida-limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.yellowpagesnepal.com/nylon2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link\n",
       "0  https://www.yellowpagesnepal.com/abhi-raj-thre...\n",
       "1       https://www.yellowpagesnepal.com/dowellsonic\n",
       "2       https://www.yellowpagesnepal.com/puantistres\n",
       "3  https://www.yellowpagesnepal.com/bahuvida-limited\n",
       "4         https://www.yellowpagesnepal.com/nylon2018"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the class names that contain the data we want to scrape\n",
    "class_names = ['cat-content', 'filter-content ml-3', 'paging', 'add-image']\n",
    "\n",
    "# Initialize the LinkScraper with the base URL and the specified class names\n",
    "scraper = LinkScraper(base_url, class_names)\n",
    "\n",
    "# Perform the scraping process and collect the links\n",
    "links_df = scraper.get_dataframe()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "links_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Data Extraction\n",
    "\n",
    "With the list of relevant links in hand, the next step is to extract detailed information from each linked page. The `DataScraper` class is designed for this purpose. It will visit each URL we collected and parse the page's content to extract the data fields we are interested in, such as business names, addresses, contact information, and any other details provided on the page.\n",
    "\n",
    "This extracted data will form the basis of our dataset, which will be used to answer questions regarding [insert the types of questions or analysis you plan to conduct with the data, such as business distribution, contact information availability, etc.].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.yellowpagesnepal.com/abhi-raj-thresher-manufacturers-and-treders\n",
      "Scraping https://www.yellowpagesnepal.com/dowellsonic\n",
      "Scraping https://www.yellowpagesnepal.com/puantistres\n",
      "Scraping https://www.yellowpagesnepal.com/bahuvida-limited\n",
      "Scraping https://www.yellowpagesnepal.com/nylon2018\n",
      "Scraping https://www.yellowpagesnepal.com/butwal-krishi-yantra-ghar\n",
      "Scraping https://www.yellowpagesnepal.com/1\n",
      "Scraping https://www.yellowpagesnepal.com/shengzhou-fusheng-machinery-and-electrics\n",
      "Scraping https://www.yellowpagesnepal.com/comeonbaby1\n",
      "Scraping https://www.yellowpagesnepal.com/zhejiang-jinxia-new-material-technology-co-ltd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated_date</th>\n",
       "      <th>views</th>\n",
       "      <th>description</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>website</th>\n",
       "      <th>reviews</th>\n",
       "      <th>related_categories</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>fax_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oct 20, 2017</td>\n",
       "      <td>3158</td>\n",
       "      <td>We are manufacturer of multi crop thresher and...</td>\n",
       "      <td>91-9587969826</td>\n",
       "      <td>Abhijitpandey555@gmail.com</td>\n",
       "      <td></td>\n",
       "      <td>No review posted</td>\n",
       "      <td>Agricultural Equipment &amp; Implements</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 21, 2017</td>\n",
       "      <td>2525</td>\n",
       "      <td>HANGZHOU DOWELL ULTRASONIC TECHNOLOGY CO.,LTD ...</td>\n",
       "      <td>86-86-571-23289358</td>\n",
       "      <td>davidwang@dowellsonic.com</td>\n",
       "      <td>http://www.dowellsonic.com/</td>\n",
       "      <td>No review posted</td>\n",
       "      <td>Agricultural Equipment &amp; Implements</td>\n",
       "      <td></td>\n",
       "      <td>86-571-23289358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 27, 2017</td>\n",
       "      <td>2069</td>\n",
       "      <td>Shanghai L&amp;H International Co., Ltd. is an int...</td>\n",
       "      <td>692-86-21-67186908</td>\n",
       "      <td>Sales@gdbr-bearing.com</td>\n",
       "      <td>http://www.gdbr-bearing.com</td>\n",
       "      <td>No review posted</td>\n",
       "      <td>Agricultural Equipment &amp; Implements</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 26, 2018</td>\n",
       "      <td>2268</td>\n",
       "      <td>Bahuvida Group is an Indian multinational cong...</td>\n",
       "      <td>91-+919398671645, 91-9398671645</td>\n",
       "      <td>bahuvidalimited@gmail.com</td>\n",
       "      <td></td>\n",
       "      <td>No review posted</td>\n",
       "      <td>Agricultural Equipment &amp; Implements</td>\n",
       "      <td>500034</td>\n",
       "      <td>+91-40-23558850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 28, 2018</td>\n",
       "      <td>2485</td>\n",
       "      <td>Huzhou Hengxin Label Manufacture Co.,Ltd. is l...</td>\n",
       "      <td>86-86-572-3773115, 86-86-13666518088</td>\n",
       "      <td>info@hengxin-label.com</td>\n",
       "      <td>http://www.hengxin-label.com/</td>\n",
       "      <td>No review posted</td>\n",
       "      <td>Agricultural Equipment &amp; Implements</td>\n",
       "      <td></td>\n",
       "      <td>86-572-3771088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   updated_date  views                                        description  \\\n",
       "0  Oct 20, 2017   3158  We are manufacturer of multi crop thresher and...   \n",
       "1  Dec 21, 2017   2525  HANGZHOU DOWELL ULTRASONIC TECHNOLOGY CO.,LTD ...   \n",
       "2  Dec 27, 2017   2069  Shanghai L&H International Co., Ltd. is an int...   \n",
       "3  Apr 26, 2018   2268  Bahuvida Group is an Indian multinational cong...   \n",
       "4  Apr 28, 2018   2485  Huzhou Hengxin Label Manufacture Co.,Ltd. is l...   \n",
       "\n",
       "                                  phone                       email  \\\n",
       "0                         91-9587969826  Abhijitpandey555@gmail.com   \n",
       "1                    86-86-571-23289358   davidwang@dowellsonic.com   \n",
       "2                    692-86-21-67186908      Sales@gdbr-bearing.com   \n",
       "3       91-+919398671645, 91-9398671645   bahuvidalimited@gmail.com   \n",
       "4  86-86-572-3773115, 86-86-13666518088      info@hengxin-label.com   \n",
       "\n",
       "                         website           reviews  \\\n",
       "0                                 No review posted   \n",
       "1    http://www.dowellsonic.com/  No review posted   \n",
       "2    http://www.gdbr-bearing.com  No review posted   \n",
       "3                                 No review posted   \n",
       "4  http://www.hengxin-label.com/  No review posted   \n",
       "\n",
       "                    related_categories postal_code       fax_number  \n",
       "0  Agricultural Equipment & Implements                               \n",
       "1  Agricultural Equipment & Implements              86-571-23289358  \n",
       "2  Agricultural Equipment & Implements                               \n",
       "3  Agricultural Equipment & Implements      500034  +91-40-23558850  \n",
       "4  Agricultural Equipment & Implements               86-572-3771088  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the DataScraper class from the webscraping module\n",
    "# (assuming it's in the same package as LinkScraper)\n",
    "from webscraping import DataScraper\n",
    "\n",
    "# Instantiate the DataScraper\n",
    "data_scraper = DataScraper()\n",
    "\n",
    "# Scrape detailed data from each link\n",
    "# (Assuming your LinkScraper has a method to get a list of links)\n",
    "links = links_df['Link'].tolist()[:10]  # Convert the 'Link' column of your DataFrame to a list\n",
    "data_scraper.scrape_sites(links)   # Scrape data from the list of links\n",
    "\n",
    "# Convert the scraped data to a DataFrame\n",
    "detailed_data_df = data_scraper.to_dataframe()\n",
    "\n",
    "# Display the first few rows of the detailed data DataFrame to ensure it looks correct\n",
    "detailed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to detailed_scraped_data.csv\n",
      "Detailed scraped data has been saved to detailed_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename for the CSV of detailed data\n",
    "detailed_csv_filename = 'detailed_scraped_data.csv'\n",
    "\n",
    "# Save the detailed data to a CSV file\n",
    "data_scraper.save_to_csv(detailed_csv_filename)\n",
    "\n",
    "# Confirm saving the file\n",
    "print(f\"Detailed scraped data has been saved to {detailed_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Exploration\n",
    "\n",
    "Now that we have our detailed dataset, let's perform some initial explorations to understand what we have collected. We will look at the data types, check for missing values, and summarize the dataset to ensure its integrity and readiness for analysis.\n",
    "\n",
    "We will also describe each field to clarify what they represent and how they can be used for answering our questions or providing insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   updated_date        10 non-null     object\n",
      " 1   views               10 non-null     int64 \n",
      " 2   description         10 non-null     object\n",
      " 3   phone               10 non-null     object\n",
      " 4   email               10 non-null     object\n",
      " 5   website             10 non-null     object\n",
      " 6   reviews             10 non-null     object\n",
      " 7   related_categories  10 non-null     object\n",
      " 8   postal_code         10 non-null     object\n",
      " 9   fax_number          10 non-null     object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "updated_date          0\n",
       "views                 0\n",
       "description           0\n",
       "phone                 0\n",
       "email                 0\n",
       "website               0\n",
       "reviews               0\n",
       "related_categories    0\n",
       "postal_code           0\n",
       "fax_number            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the info of the DataFrame to get an overview of the data types and missing values\n",
    "detailed_data_df.info()\n",
    "\n",
    "# Display statistical summaries for numerical fields in the DataFrame\n",
    "detailed_data_df.describe()\n",
    "\n",
    "# If there are categorical data fields, consider including frequency counts for those as well\n",
    "# detailed_data_df['category_field'].value_counts()\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "detailed_data_df.isnull().sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
